<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Calls for Papers | MIS Quarterly</title>
        <link>https://callsforpapers.org/journal/mis-quarterly</link>
        <description>Latest calls for papers for MIS Quarterly.</description>
        <lastBuildDate>Sun, 07 Sep 2025 03:08:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <image>
            <title>Calls for Papers | MIS Quarterly</title>
            <url>https://callsforpapers.org/public/favicon/android-chrome-96x96.png</url>
            <link>https://callsforpapers.org/journal/mis-quarterly</link>
        </image>
        <copyright>Calls for Papers © 2025</copyright>
        <item>
            <title><![CDATA[Artificial Intelligence-Information Assurance Nexus: The Future of Information Systems Security, Privacy, and Quality]]></title>
            <link>https://callsforpapers.org/call/misq-ai-ia-nexus</link>
            <guid>misq-ai-ia-nexus</guid>
            <pubDate>Wed, 16 Oct 2024 05:11:12 GMT</pubDate>
            <content:encoded><![CDATA[<div>
    
        
        <p><strong>Rui Chen</strong>, Iowa State University</p>
        
        <p><strong>Juan Feng</strong>, Tsinghua University</p>
        
        <p><strong>Miguel Godinho de Matos</strong>, Católica Lisbon School of Business &amp; Economics</p>
        
        <p><strong>Carol Hsu</strong>, University of Sydney</p>
        
        <p><strong>H. Raghav Rao</strong>, University of Texas at San Antonio</p>
        
    
    
    <p>Digital threats continue to impede information assurance. Many issues in information assurance have arisen in the last decade or two, including risk management, information quality, intellectual property, privacy protection, compliance with regulations, and continuity of operations (Mahmood et al., 2010; Forrest, 2023). As a result, protecting information has become a global priority, and collaborative efforts are being made to prevent, detect, and react to threats to information quality, authenticity, integrity, confidentiality, and availability (European Parliament, 2018; White House, 2023a). As society steps into the age of generative AI (GenAI) (Dennehy et. al., 2023), fresh challenges and opportunities are arising in the realms of information security, privacy, and quality. Questions have emerged regarding the role and intended/unintended consequences of GenAI in information assurance. GenAI is believed to pose a paradox, serving as a dual-edged sword in the realm of information assurance (Robidoux, 2024).</p>
    
    <p>GenAI creates new content, whereas traditional AI mostly makes predictions and classifications based on existing datasets. GenAI is designed to reason and operate independently across various domains, whereas traditional AI focuses on narrow tasks (e.g., playing chess and translating languages by following specific rules). In addition, GenAI works with multiple data modalities (e.g., text, images, and videos), whereas traditional AI primarily functions in a single mode of data. These new capabilities of GenAI open new possibilities for its applications in a wide range of areas. GenAI models can range from generalized models to domain-specific models that automate tasks and generate content adhering to industry-specific terminologies, context-specialized knowledge, and tailored experiences. Its power has sparked discussions on ethics and societal questions regarding the potential impact on employment, bias, privacy, and human-AI relationships.</p>
    
    <p>The emergence of GenAI is poised to exert a profound impact on assurance (Barrett et al., 2023; Sun et al., 2023). On the one hand, GenAI has been recognized for its ability to bolster information assurance. The IBM Institute for Business Value (2024) commented that GenAI has the potential to strengthen business defenses, accelerate security processes, and identify emerging threats as they arise. Studies have also noted that GenAI may be able to address information management challenges, including quality (Bhatti, 2024). On the other hand, GenAI heightens the potency of existing threats, allows the fabrication of false information, fuels intellectual property theft, and poses challenges to governance and compliance. The 2024 February deepfake fraud incident in Hong Kong is a case in point (Chen &amp; Magramo, 2024). Even unexpected users can threaten the protection of data, which is manifested by examples of employees sharing confidential data with GenAI models. Industry reports from Forrester (2023), Cisco (2024), and the IBM Institute for Business Value (2024) have highlighted GenAI-induced risks to information assurance as a major threat to firms’ adoption and implementation of GenAI initiatives. Similar concerns have been acknowledged from a government perspective in the 2023 U.S. Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (White House, 2023b) and the 2023 congressional research report: Generative Artificial Intelligence and Data Privacy: A Primer (Congressional Research Service, 2023).</p>
    
    <p>Examples of how GenAI may exacerbate information assurance issues include:</p>
    
    <p>1. **Sophisticated human-deception attacks:** Cybercriminals can use GenAI to compromise businesses by writing targeted emails. In addition, GenAI can create deepfakes and voice clones, resulting in “vishing” that uses phone calls and voice messages to trick people into sharing sensitive information.</p>
    
    <p>2. **Hallucination and confabulation:** GenAI is known to create incorrect information that is seemingly correct. In addition, attackers may trick GenAI into recommending unverified software code packages to unexpected users. When attackers embed malicious codes into packages endorsed by GenAI, users may unwittingly download and utilize these harmful codes, creating security vulnerabilities ripe for exploitation.</p>
    
    <p>3. **Intellectual property theft:** GenAI can create materials that violate intellectual property rights. For example, GenAI can create content that resembles existing copyrighted materials, resulting in legal ramifications and conflicts.</p>
    
    <p>4. **Challenges in regulation and compliance:** Keeping GenAI models in check is subject to considerable hurdles because of how intricate and swiftly they evolve. Ensuring compliance with data protection laws and standards will become increasingly difficult as GenAI becomes more autonomous and capable of making independent decisions.</p>
    
    <p>Another source of threats to information assurance stems from attacks that are designed to target the way GenAI systems are trained and expected to be used. Many of these attacks can be mitigated by explicitly integrating information assurance considerations when designing GenAI systems. For example, GenAI tools may be subject to:</p>
    
    <p>1. **Unreliable training data:** A substantial amount of training data is employed in constructing large language models (LLMs). Yet this data may be of low quality and is often unverified. The security of the models is influenced by the quality of the training data, paving the way for potential vulnerabilities, unauthorized access, and compromises regarding sensitive information.</p>
    
    <p>2. **Data poisoning:** GenAI needs to be trained and tuned on inputs and outputs. Data poisoning occurs when inputs are manipulated to alter or corrupt the training data in LLMs, which consequently impacts the desired outputs of the overall system.</p>
    
    <p>3. **Security leaks, inference attacks, and knowledge phishing:** Security leaks in the context of GenAI refer to the unintended disclosure of sensitive information embedded within a model itself or through its responses. This is also known as inference attacks or knowledge phishing.</p>
    
    <p>4. **Prompt injections:** Prompt injections occur when malicious inputs are provided to an AI system to manipulate its output or to execute unintended actions.</p>
    
    <p>Cisco (2024) found that 92% of organizations “see GenAI as fundamentally different, requiring new techniques to manage data and risks.” The 2023 U.S. Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence calls for actions on refining GenAI by mitigating information assurance issues (White House, 2023b). Worldwide efforts are being made on these fronts to protect LLMs against threats of information fabrication, system misuse, privacy breaches, etc. Gartner recommends mitigation strategies, which include “establishing a governance entity and workflow, monitoring and blocking access, communicating acceptable use policies, exploring prompt engineering and API integrations, and prioritizing private hosting options” (Robidoux, 2024). However, there are growing concerns that excessive focus and regulation on data security and privacy may stifle and slow the advancement of GenAI, especially in terms of the European Union’s AI Act (Timis, 2023).</p>
    
    <p>The relationship between GenAI and information assurance is depicted below.</p>
    
    
    <h2>Potential topics</h2>
    <ul>
        
        <li>What factors influence individuals’ security and privacy behavior in the presence of GenAI tools?</li>
        
        <li>How can we predict, analyze, and counteract the emerging threats to GenAI models?</li>
        
        <li>How can economic analysis contribute to combating information assurance threats in GenAI?</li>
        
        <li>What are the managerial strategies and their effectiveness in addressing GenAI-induced issues on data security and privacy?</li>
        
        <li>What are the key principles in attributing accountability and responsibilities for the risks in GenAI model output?</li>
        
        <li>Individual behaviors</li>
        
        <li>Organizational practices</li>
        
        <li>Societal impacts</li>
        
        <li>Risk management</li>
        
        <li>Investments in assurance</li>
        
        <li>Market effects</li>
        
        <li>Attacker analysis</li>
        
    </ul>
    
    
    <h2>Timeline</h2>
    <ul>
        
        <li>January 20, 2025: Abstract Proposal Deadline</li>
        
        <li>March 31, 2025: Feedback on abstracts</li>
        
        <li>July 11, 2025: Paper development workshop (virtual)</li>
        
        <li>October 31, 2025: Stage 1 Submission Deadline</li>
        
        <li>January 31, 2026: First-round decisions</li>
        
        <li>February 1, 2026: Workshop for authors with first-round revise-and-resubmit</li>
        
        <li>May 31, 2026: Second-round revisions due</li>
        
        <li>August 31, 2026: Second-round decisions</li>
        
        <li>November 30, 2026: Final revisions due</li>
        
        <li>February 28, 2027: Final revisions</li>
        
    </ul>
    
    
    <h2>Associate editors</h2>
    <ul>
        
        <li><strong>Panagiotis Adamopoulos</strong>, Emory University</li>
        
        <li><strong>Jingjing Li</strong>, University of Virginia</li>
        
        <li><strong>Rodrigo Belo</strong>, Nova School of Business and Economics</li>
        
        <li><strong>Huigang Liang</strong>, University of Memphis</li>
        
        <li><strong>Indranil Bose</strong>, NEOMA</li>
        
        <li><strong>Alexander Maedche</strong>, Karlsruhe Institute of Technology</li>
        
        <li><strong>Lemuria Carter</strong>, University of Sydney</li>
        
        <li><strong>Ning Nan</strong>, University of British Columbia</li>
        
        <li><strong>Christy Cheung</strong>, Hong Kong Baptist University</li>
        
        <li><strong>Jella Pfeiffer</strong>, University of Stuttgart</li>
        
        <li><strong>Rahul De’</strong>, Indian Institute of Management Bangalore</li>
        
        <li><strong>Dandan Qiao</strong>, National University of Singapore</li>
        
        <li><strong>Amany Elbanna</strong>, University of Sussex</li>
        
        <li><strong>Sagar Samtani</strong>, Indiana University</li>
        
        <li><strong>Uri Gal</strong>, University of Sydney</li>
        
        <li><strong>Anastasia Sergeeva</strong>, Vrije Universiteit Amsterdam</li>
        
        <li><strong>Weiyin Hong</strong>, Hong Kong University of Science and Technology</li>
        
        <li><strong>Maha Shaikh</strong>, ESADE Business School</li>
        
        <li><strong>Nina Huang</strong>, University of Miami</li>
        
        <li><strong>Paolo Spagnoletti</strong>, Luiss Business School</li>
        
        <li><strong>Hartmut Höhle</strong>, University of Mannheim</li>
        
        <li><strong>Rohit Valecha</strong>, University of Texas at San Antonio</li>
        
        <li><strong>Allen Johnston</strong>, University of Alabama</li>
        
        <li><strong>Jing Wang</strong>, Hong Kong University of Science and Technology</li>
        
        <li><strong>Arpan Kar</strong>, Indian Institute of Technology</li>
        
        <li><strong>Jingguo Wang</strong>, University of Texas at Arlington</li>
        
        <li><strong>Juhee Kwon</strong>, City University of Hong Kong</li>
        
        <li><strong>Hong Xu</strong>, Hong Kong University of Science and Technology</li>
        
        <li><strong>Atanu Lahiri</strong>, University of Texas at Dallas</li>
        
        <li><strong>Heng Xu</strong>, University of Florida</li>
        
        <li><strong>Alvin Leung</strong>, City University of Hong Kong</li>
        
        <li><strong>Niam Yaraghi</strong>, University of Miami</li>
        
        <li><strong>Ting Li</strong>, Erasmus University</li>
        
        <li><strong>Cathy Liu Yang</strong>, HEC Paris</li>
        
        <li><strong>Yingjie Zhang</strong>, Peking University</li>
        
    </ul>
    
</div>]]></content:encoded>
            <author>MIS Quarterly (MISQ)</author>
        </item>
        <item>
            <title><![CDATA[The Institutional Press in the Digital Age]]></title>
            <link>https://callsforpapers.org/call/misq-the-institutional-press-in-the-digital-age</link>
            <guid>misq-the-institutional-press-in-the-digital-age</guid>
            <pubDate>Tue, 12 Dec 2023 05:15:06 GMT</pubDate>
            <content:encoded><![CDATA[<div>
    
        
        <p><strong>Ahmed Abbasi</strong>, University of Notre Dame</p>
        
        <p><strong>Brad N. Greenwood</strong>, George Mason University</p>
        
        <p><strong>Melissa Mazmanian</strong>, University of California, Irvine</p>
        
        <p><strong>Shaila Miranda</strong>, University of Arkansas</p>
        
        <p><strong>Robert Seamans</strong>, New York University</p>
        
    
    
    <p>Over the last 20 years, ongoing waves of digitalization have decimated the traditional business model of the news and fundamentally changed how the news, or more formally, the ‘institutional press’, works. Indeed, ever since reserved frequencies were gifted to television broadcasters in the 1950s, on the condition that they inform the public of current events, the subsidy underpinning newspapers and other forms of institutional media has slowly eroded. Like many other industries, the internet has accelerated this phenomenon. Not only has the hyper-targeted advertising facilitated by social media and other platforms functionally eroded the subsidy model to its breaking point; but the costless transmission of data facilitated by the internet has increased geographic scope of dominant players, permitting them to reach beyond their original markets and squeeze content producers across the globe. Against this backdrop, it is hard to overstate the importance of this &#39;crisis of the institutional press&#39;. The news provides our primary means for understanding the world around us. Societies desperately need a well-functioning institutional press to tackle the many societal, economic, and environmental challenges we all face.</p>
    
    <p>The first day of core courses usually begins with one of four motivating examples: the decline of incumbent sellers in favor of digital platforms, the increasing irrelevance of diseconomies of scale and the rise of digital monopolies, the rise of social media and user-generated content, or the decline of the newspaper industry. Yet, as these classes continue to discuss the opportunities firms have in the digital age and teach students to implement advanced analytics to more effectively mine business value from data, the decline of institutional media often fades into the background.</p>
    
    <p>This phenomenon-driven special issue is motivated by the view that our students, colleagues, and society urgently need a better understanding of the causes and consequences of the changing nature of news in the digital era and potential solutions going forward. The special issue takes an interdisciplinary perspective, bringing together insights from across the broader information, managerial, and organizational sciences.</p>
    
    <p>This failure to discuss the implications of the decline of institutional news media is troubling. Not only has the Fourth Estate historically served to counterbalance institutions with a monopoly on force and morality, it has been a cornerstone of democratic republics for centuries. These claims are not idle musings. News media outlets have been shown to influence many societal outcomes, from government agendas to public opinion to voting behavior. The Fourth Estate mediates the attention granted to social movements and can influence the strategic management of organizations. Institutional media can also prompt changes in corporate governance: it can shape the valuation of firms at IPO, influence firm founding, confer legitimacy on industries, and even elevate de novo technological innovations in the public consciousness.</p>
    
    <p>Yet, seismic changes have assaulted the free press as we understand it. The late 20th century witnessed an increasing concentration in ownership of news outlets, leading to elevated reliance on advertising revenue that biased content. The recent history of the institutional press is interwoven with the history of digital technology. Initially, the World Wide Web served largely as a vehicle for the dissemination of news produced by professional news organizations, extending their reach. In time, the ensuing competition for reader attention shifted the gatekeeping function from professional news organizations to online content curators. Contemporary media coverage became more selective and influenced by market actors. With the advent of social media, user-generated content further usurped the gatekeeping role of professional news organizations. Moreover, public subsidy for the Fourth Estate was undermined by social media, accelerating the control of dominant players on public discourse and hollowing the local publishing industry. At the same time, social media has afforded citizen journalists the ability to counter-balance the biases of professional news organizations.</p>
    
    <p>Even more recently, society has witnessed a demonstrable shift towards the &#39;post-truth era,&#39; in which populist, tribalist, and anti-&#39;mainstream media&#39; rhetoric proliferates. While the blockchain has been heralded as a way of remaking the institutional press in the digital era, we have little systematic understanding of its efficacy. All the while, the process of news construction and dissemination is being disrupted by algorithms, machine learning, and artificial intelligence. The long-term implications of these AI tools on the institutional press are unknown. Indeed, we are witnessing intersections of the evolutionary paths of technology and the institutional press in ways that are fundamentally changing the &#39;freedom of the press&#39; and the complex network that includes journalists, software engineers, relational databases, and social media platforms which form it; along with prevailing norms, values, and institutional logics of a particular sociotechnical moment.</p>
    
    <p>Research has only begun to address these changes. The purpose of this Special Issue is to address this gap in scholarship head on and to inform stakeholders about how changes in institutional media are affecting society at the intersection of business, technology, and public policy. To this end, we invite scholarship that helps academia and society comprehend the major changes taking place within the institutional press, why those changes are occurring, and what the consequences of those changes are; and work together toward a more positive future for the institutional press.</p>
    
    <p>We encourage an equally diverse breadth of scholars to submit their work to this special issue.</p>
    
    
    <h2>Potential topics</h2>
    <ul>
        
        <li>The changing nature of the press, news media as an institution, and the consequences of those changes.</li>
        
        <li>The functioning of, and implications for, non-traditional digital era news sources.</li>
        
        <li>What constitutes news in the digital era?</li>
        
        <li>The interaction of social and institutional media.</li>
        
        <li>The role of professional standards and gatekeeping in today’s news media ecosystem and mechanisms to support them.</li>
        
        <li>Sociotechnical approaches to understanding the intersections and dependencies between technologies, institutional forces, values, and norms in relation to freedom of the press.</li>
        
        <li>Designing and assessing IT artifacts (e.g., generative AI, algorithms and computational methods, blockchain) towards an aspirational institutional press.</li>
        
        <li>The news as a dynamic construct across time and space, and the consequent implications for content generation and consumption.</li>
        
        <li>The news as a societal information system.</li>
        
    </ul>
    
    
    <h2>Timeline</h2>
    <ul>
        
        <li>April 30, 2024: Optional abstract submission due</li>
        
        <li>May 30, 2024: Optional abstract feedback via email</li>
        
        <li>August 5, 2024: Invited five-page abstract for AOM Workshop due</li>
        
        <li>August 9, 2024: Paper Development Workshop at AOM</li>
        
        <li>December 1, 2024: Full Paper Submission Deadline</li>
        
        <li>March 15, 2025: First-round decisions expected</li>
        
        <li>May 30, 2025: Revision Plan Meeting with SI Editors</li>
        
        <li>July 15, 2025: Second-round revisions due</li>
        
        <li>October 15, 2025: Second-round decisions expected</li>
        
        <li>February 15, 2026: Third- and final revisions submissions due</li>
        
        <li>May 15, 2026: Final decisions expected</li>
        
    </ul>
    
    
    <h2>Associate editors</h2>
    <ul>
        
        <li><strong>Mike Annay</strong>, University of Southern California</li>
        
        <li><strong>Jens Foerderer</strong>, Technische Universität München</li>
        
        <li><strong>Anand Gopal</strong>, National Technical University of Singapore</li>
        
        <li><strong>Brent Kitchens</strong>, University of Virginia</li>
        
        <li><strong>Gene Moo Lee</strong>, UBC Sauder School of Business</li>
        
        <li><strong>Attila Marton</strong>, Copenhagen Business School</li>
        
        <li><strong>Jeffrey Nickerson</strong>, Stevens Institute of Technology</li>
        
        <li><strong>Christopher Parker</strong>, American University</li>
        
        <li><strong>Caitlin Petre</strong>, Rutgers University</li>
        
        <li><strong>Christian Peukert</strong>, HEC Lausanne</li>
        
        <li><strong>Aleš Popovič</strong>, NEOMA Business School</li>
        
        <li><strong>Jui Ramaprasad</strong>, University of Maryland</li>
        
        <li><strong>Imke Reimers</strong>, Cornell University</li>
        
        <li><strong>Jie Ren</strong>, Fordham University</li>
        
        <li><strong>Gaurav Sabnis</strong>, Stevens Institute of Technology</li>
        
        <li><strong>Ananya Sen</strong>, Carnegie Mellon University</li>
        
        <li><strong>Jananki Srinivasan</strong>, IIIT-Bangalore</li>
        
        <li><strong>Xiao Xiao</strong>, Copenhagen Business School</li>
        
        <li><strong>Yi Yang</strong>, HKUST</li>
        
        <li><strong>Nan Zhang</strong>, University of Florida</li>
        
        <li><strong>Aljona Zorina</strong>, IESEG</li>
        
    </ul>
    
</div>]]></content:encoded>
            <author>MIS Quarterly (MISQ)</author>
        </item>
        <item>
            <title><![CDATA[Registered Reports]]></title>
            <link>https://callsforpapers.org/call/misq-registered-reports</link>
            <guid>misq-registered-reports</guid>
            <pubDate>Thu, 05 Jan 2023 05:15:06 GMT</pubDate>
            <content:encoded><![CDATA[<div>
    
        
        <p><strong>Shuk Ying Ho</strong>, Australian National University</p>
        
        <p><strong>Jan Recker</strong>, University of Hamburg</p>
        
        <p><strong>Chee-Wee Tan</strong>, Copenhagen Business School</p>
        
        <p><strong>Anthony Vance</strong>, Virginia Tech</p>
        
        <p><strong>Han Zhang</strong>, Georgia Tech</p>
        
    
    
    <p>An irony of science is that, despite our devotion to evidence, there is little evidence underpinning many aspects of the journal review process. As part of our commitment to continually improving our review processes at MIS Quarterly, this special issue aims to obtain evidence regarding the merits of a recent innovation in the review process—registered reports.</p>
    
    <p>While the registered report model is relatively new, it has been adopted by over 200 journals across the sciences. Business and Information Systems Engineering was the first (and so far, lone) IS journal to adopt this model. Other early adopters across the business fields include Journal of Accounting Research, Academy of Management Discoveries, and Leadership Quarterly.</p>
    
    <p>Our goal in this special issue is to learn if the registered report model should be available as an ongoing model for MISQ, as a supplement to our existing options. While we see a lot of promise in the model, we plan to test it first to learn if/how it can best suit our journal.</p>
    
    <p>The registered report model involves a 2-stage ‘acceptance’ process: a conditional acceptance before data collection, followed by an acceptance if the authors follow the agreed plan. Compared to a normal review process, there are two main differences: Pre/pilot data may (or may not) have been collected before conditional acceptance, but the main data will not have been collected prior to the conditional acceptance being offered. The paper cannot be rejected due to its results.</p>
    
    <p>Early tests of the registered report model across the sciences are yielding positive results, especially on the dimensions of bias reduction and investment motivation.</p>
    
    <p>Submissions to this special issue will be reviewed in a three-step process focusing on different criteria. Step 1 involves examining the submission proposals for suitability. Step 2 is the Stage 1 Review based on criteria for conditional acceptance. Step 3 is the Stage 2 Review based on criteria for final acceptance, where the actual results will be considered but will not affect acceptance as long as the agreed processes were followed.</p>
    
    
    <h2>Potential topics</h2>
    <ul>
        
        <li>Registered report model</li>
        
        <li>Evidence in journal review process</li>
        
        <li>Bias reduction in peer review</li>
        
        <li>Investment motivation in research</li>
        
        <li>Hypothesized models and empirical testing in IS research</li>
        
    </ul>
    
    
    <h2>Timeline</h2>
    <ul>
        
        <li>Invalid DateTime: Stage 2 submissions due within 9 months of Stage 1 decision</li>
        
        <li>Invalid DateTime: Special Issue Publication, Editorial, and Showcase Event</li>
        
        <li>February 20, 2023: Introductory workshop (optional)</li>
        
        <li>July 1, 2023: Proposal Deadline</li>
        
        <li>October 1, 2023: Stage 1 Submission Deadline</li>
        
        <li>December 15, 2023: Stage 1 initial decisions expected</li>
        
        <li>January 1, 2024: Special Issue workshop for Stage 1 authors</li>
        
        <li>October 1, 2024: Stage 1 submissions must receive a conditional acceptance no later than this date</li>
        
    </ul>
    
    
</div>]]></content:encoded>
            <author>MIS Quarterly (MISQ)</author>
        </item>
        <item>
            <title><![CDATA[Digital Technologies and Social Justice]]></title>
            <link>https://callsforpapers.org/call/misq-digital-technologies-and-social-justice</link>
            <guid>misq-digital-technologies-and-social-justice</guid>
            <pubDate>Sat, 01 Jan 2022 05:15:06 GMT</pubDate>
            <content:encoded><![CDATA[<div>
    
    
    
    
    
</div>]]></content:encoded>
            <author>MIS Quarterly (MISQ)</author>
        </item>
    </channel>
</rss>