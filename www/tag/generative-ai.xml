<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Calls for Papers | Tag: generative ai</title>
        <link>https://callsforpapers.org/tag/generative-ai</link>
        <description>Latest calls for papers tagged with 'generative ai'.</description>
        <lastBuildDate>Fri, 06 Feb 2026 04:22:09 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <image>
            <title>Calls for Papers | Tag: generative ai</title>
            <url>https://callsforpapers.org/public/favicon/android-chrome-96x96.png</url>
            <link>https://callsforpapers.org/tag/generative-ai</link>
        </image>
        <copyright>Calls for Papers © 2025</copyright>
        <item>
            <title><![CDATA[Generative AI as Driver of Change in Media]]></title>
            <link>https://callsforpapers.org/call/jmis-generative-ai-as-driver-of-change-in-media</link>
            <guid>jmis-generative-ai-as-driver-of-change-in-media</guid>
            <pubDate>Sat, 22 Nov 2025 03:12:30 GMT</pubDate>
            <content:encoded><![CDATA[<div>
    
        
        <p><strong>Thomas Hess</strong>, University of Munich (LMU)</p>
        
        <p><strong>Ioanna Constantiou</strong>, Copenhagen Business School</p>
        
        <p><strong>Niki Panteli</strong>, Lancaster University</p>
        
    
    
    <p>Generative AI (GenAI) has rapidly become a general-purpose technology that reshapes how information is created, curated, and consumed. GenAI broadly refers to a class of AI models that generate seemingly new content in the form of text, images, audio, or video. In the media context, where value is built around the provision and use of content, GenAI has attracted particular attention. For instance, it enables the near-instant creation of journalistic articles, marketing texts, or audiovisual material, and it supports personalization by dynamically adapting media offerings to individual user preferences. The advent of the Internet had already marked a profound transformation in the delivery and consumption of content. It made user-generated content possible, catalyzed multi-sided platforms, and enabled unprecedented personalization. This transformation brought new players into the media sector, as technology companies entered the market and traditional media firms were forced to develop significant digital competencies for the first time.</p>
    
    <p>GenAI is expected to have an equally profound impact on the media industry by expanding complementary innovation, lowering barriers for content creation, and altering the economics of matching and recommendation at scale. Despite recent advances, our knowledge is still limited. Existing research has begun to shed light on the impact of GenAI on textual news app users’ willingness to pay, yet it is unknown whether similar effects extend to audiovisual content. Moreover, there are initial indications of how journalists’ productivity may change with the use of GenAI. At the same time, the potential for entirely new GenAI-based products remains largely unexplored. In particular, little is known about the extent to which audience discussions can be moderated and managed, or about the new forms of public media provision that GenAI might enable. These questions are especially pressing given the central role of media in shaping public opinion and broader societal developments, including political attitudes.</p>
    
    <p>The aim of this special issue is to advance IS research on this emerging field. We invite contributions that examine the role of GenAI in the provision and use of media offerings. Analyses may focus on individuals, organizations, or industries. Studies may address GenAI on the level of systems, their effects, or their management. Submissions should be firmly grounded in the technology itself and its implications for media ecosystems. This special issue aims to stimulate innovative investigations of the transformative role of GenAI in the provisioning and use of public media. In contrast to closed settings, such as private messaging services, the recipients of public communication cannot be predetermined or exhaustively specified in advance. Accordingly, the domain of interest spans both online media, including digital platforms and social media, and traditional media such as print and television. We welcome qualitative and quantitative empirical studies as well as design-oriented research. Submissions should provide a clear academic contribution by advancing theory and knowledge in the Information Systems discipline. While practical relevance and managerial implications are highly valued, they are not sufficient on their own; academic advancement is essential.</p>
    
    
    <h2>Potential topics</h2>
    <ul>
        
        <li>Provision of Content for the Media</li>
        
        <li>Use of Content provided by the Media</li>
        
        <li>Embedding of the Media in Society</li>
        
    </ul>
    
    
    <h2>Timeline</h2>
    <ul>
        
        <li>December 1, 2025: Full paper submission opens</li>
        
        <li>April 30, 2026: Full paper submission closes</li>
        
        <li>June 30, 2026: Desk check</li>
        
        <li>September 30, 2026: Feedback on the first version</li>
        
        <li>January 31, 2027: Submission revision 1</li>
        
        <li>April 30, 2027: Feedback on revision 1</li>
        
        <li>June 30, 2027: Submission revision 2</li>
        
        <li>July 31, 2027: Final decision</li>
        
    </ul>
    
    
</div>]]></content:encoded>
            <author>Journal of Management Information Systems (JMIS)</author>
        </item>
        <item>
            <title><![CDATA[Unpacking the Multifaceted Impact of Generative Artificial Intelligence on Organisations]]></title>
            <link>https://callsforpapers.org/call/jsis-unpacking-the-multifaceted-impact-of-generative-artificial-intelligence-on-organisations</link>
            <guid>jsis-unpacking-the-multifaceted-impact-of-generative-artificial-intelligence-on-organisations</guid>
            <pubDate>Sat, 23 Aug 2025 03:09:37 GMT</pubDate>
            <content:encoded><![CDATA[<div>
    
        
        <p><strong>Jun Hwa Cheah (Jacky)</strong>, University of East Anglia</p>
        
        <p><strong>Brad McKenna</strong>, University of East Anglia</p>
        
        <p><strong>Shahper Richter</strong>, University of Auckland</p>
        
        <p><strong>PK Senyo</strong>, University of Southampton</p>
        
        <p><strong>Marco Marabelli</strong>, Bentley University</p>
        
    
    
    <p>This special issue examines Generative AI&#39;s dual impact on organisations, driving innovation, efficiency, and societal value while raising ethical, governance, and workforce challenges.</p>
    
    <p>Generative Artificial Intelligence (GAI) is at the forefront of technological innovation, with rapid growth and transformative potential. By 2032, the global GAI market is projected to reach $151.9 billion. This trajectory reflects the growing recognition of GAI&#39;s capabilities across multiple domains, fundamentally reshaping innovation paradigms and redefining organisational processes and structures. In particular, GAI is increasingly acknowledged as a transformative force in facilitating data-driven decision-making and optimising operational processes within and across organisations. Foundational GAI systems such as BERT, ChatGPT DALL-E, Deepseek and Gemini illustrate their adaptability and extensive applicability. These systems can execute a wide array of tasks, ranging from creative production and service delivery to organisational decision-making, offering novel opportunities for personalisation, operational efficiency, and interdisciplinary collaboration. As GAI continues to evolve, some organisations have commenced developing and disseminating regulatory frameworks to legitimise its deployment in organisational processes. There is growing interest in whether GAI can be repurposed as a strategic technology employed for advancing social justice and addressing grand challenges, from climate resilience to digital access and social welfare. At the same time, there are stakeholders, including organisational actors, that are concerned with the risks posed by GAI, such as data governance, epistemic reliability, trust, error propagation, and bias. This special issue aims to unfold strategic opportunities and challenges of GAI in organizations, networks, government bodies and society at large.</p>
    
    <p>While prior studies have examined AI more conceptually and broadly, a significant unexplored area remains, which concerns the multifaceted impacts of GAI on organisational decision-making within the information systems research. Because of the relevant strategic implications (and potentially ethical challenges) associated with implementing GAI in organisations, filling this gap becomes paramount. In particular, with this special issue we aim to stimulate research focusing on the dual nature of GAI, its simultaneous potential for value co-creation and value co-destruction in organisations; GAI presents promising opportunities and significant challenges. In particular, GAI used for automated content creation, internal reporting and predictive analytics, has the potential to improve operational efficiency by identifying workflow bottlenecks, reducing manual workload, and enabling data-driven insights into employee performance and strategic planning. With these capabilities, it can detect subtle signs of fatigue or burnout, such as slower response times, changes in communication tone, or altered work patterns. Hence it enables early intervention through tailored support or adjustments to the workload. Also, by synthesising vast amounts of information, GAI supports value co-creation and strategic agility in decision-making, promotes innovation and digital inclusion, and allows employees to focus on higher-level tasks such as problem-solving and strategic thinking. In fact, GAI can foster creativity and knowledge sharing, support employee well-being by automating repetitive tasks, and improve cross-functional collaboration. GAI can also detect subtle patterns indicative of fatigue or burnout, such as reduced response times, changes in communication tone, or shifts in work rhythms, allowing organisations to intervene early with tailored support or workload adjustments.</p>
    
    <p>However, these organisational benefits are tempered by critical concerns. The increasing reliance on opaque and complex GAI systems introduces risks related to hallucinations, diminished human oversight, and the externalisation of ethical responsibility onto non-accountable technologies. According to a 2023 global survey, 75% of companies have restricted or actively considered restricting technologies such as ChatGPT due to fears of data breaches, intellectual property loss, and declining trust in AI-generated content. More fundamentally, GAI threatens the nature of creative labour, raising questions about job security, intellectual integrity, and the automation of cognitively demanding work. GAI implementation may also generate unintended consequences for employee well-being, including role displacement, cognitive dependency, and reduced transparency in decision-making, which somehow affects the diversity, equality, and inclusion in the working environment. Concerning workplace surveillance, GAI can undermine employee autonomy by enabling constant monitoring that erodes trust and psychological safety. Employees may feel reduced to performance metrics, reflecting a shift toward Digital Taylorism, which prioritises algorithmic efficiency over human creativity. This dynamic can further intensify privacy concerns due to the opaque nature of many GAI systems, where data is often collected and used without clear consent. This will also heighten the risk of biased or discriminatory outcomes. Thus, all of these concerns highlight the potential for value co-destruction, wherein mismanaged or poorly governed GAI adoption undermines organisational integrity, ethical standards, and stakeholder trust. This resonates with recent developments in people analytics, where GAI-facilitated behavioural monitoring intersects with algorithmic control, potentially transforming managerial decision-making into a form of digital micromanagement.</p>
    
    <p>Given these growing uncertainties and tensions surrounding GAI, there is an urgent need to move beyond celebratory narratives and engage in critical, multidisciplinary inquiry into its dual-edged nature. On one hand, GAI serves as a powerful cognitive enabler, helping organisations to synthesise complex information, generate novel insights, and expand the boundaries of individual and collective knowledge. On the other hand, increasing reliance on these systems may gradually erode essential cognitive functions, such as critical thinking, independent reasoning, and problem-solving skills. Furthermore, the large-scale integration of GAI risks reinforcing existing cognitive biases, curating algorithmic filter bubbles, and narrowing exposure to diverse perspectives, thereby constraining informed decision-making. In light of these tensions, this special issue invites scholars and practitioners to adopt a perspective considering both the strategic, transformative potential and disruptive consequences of GAI. We welcome contributions that examine how GAI simultaneously enhances and challenges existing organisational frameworks and processes, ultimately reshaping the landscape of technological governance, human agency, and organisational transformation. Submissions may offer theoretical or empirical insights into the promises, ethical dilemmas, and societal shifts driven by GAI at the organisational level, including its application to grand societal challenges. We will not consider papers focusing on users, individuals, or manuscripts that do not align with the central focus of the special issue. Papers may use qualitative, quantitative, or pluralistic approaches.</p>
    
    
    <h2>Potential topics</h2>
    <ul>
        
        <li>How is the utilisation of GAI reshaping workforce structures, labour division, and professional identity in public and/or private organisations?</li>
        
        <li>How can organisations effectively balance the efficiency and productivity gains promised by GAI with the risks related to data security, intellectual property theft, and regulatory compliance challenges?</li>
        
        <li>In what ways can organisations address the ethical implications of GAI, particularly concerning its potential to diminish human oversight and decision-making capabilities, while still harnessing its benefits for enhanced operational efficiency?</li>
        
        <li>How does GAI contribute to value co-destruction within organisations, in relation to resource misallocation, ethical compromises, and potential damage to organisational integrity or stakeholder trust?</li>
        
        <li>What strategies can organisations adopt to mitigate the risks of job displacement, deskilling, and workforce inequality while still leveraging GAI for innovation and competitiveness?</li>
        
        <li>How can organisational capabilities and leadership approaches evolve to ensure a balance between fostering innovation through GAI and managing its long-term impacts on employment, creativity, and organisational culture?</li>
        
        <li>How do organisational frameworks surrounding GAI affect the reinforcement or reduction of structural inequalities, especially in marginalised communities, and what measures can be taken to ensure inclusive and equitable use of GAI technologies?</li>
        
        <li>How are corporate governance frameworks evolving in response to GAI’s ethical challenges in decision-making, and how can these frameworks protect against algorithmic biases while fostering innovation?</li>
        
        <li>What role should organisational policies play in ensuring that GAI is used transparently and responsibly, particularly in high-stakes decisions involving human resources, operations, marketing, and customer relations?</li>
        
        <li>How is GAI being used for surveillance and control in organizational contexts, and what implications does this have for employee autonomy and governance, both in the workplace and in broader governmental settings?</li>
        
        <li>What is the potential and what are the limitations of GAI adoption in organisations across emerging economies and the Global South, particularly in relation to infrastructural, educational, and data governance challenges?</li>
        
        <li>Examining how different organisations (e.g., governments, healthcare providers, charities, or social enterprises) might deploy GAI to address grand challenges such as climate-adaptation, homelessness-prevention services, healthcare, strategically serving marginalised populations, or environmental disasters.</li>
        
        <li>Assessing the emerging role of corporate sustainability offices in leveraging GAI for supply-chain net-zero scenario planning.</li>
        
    </ul>
    
    
    <h2>Timeline</h2>
    <ul>
        
        <li>January 31, 2026: Submission of extended abstracts (~1,000 words including references). Submission of an abstract is not mandatory but is strongly encouraged.</li>
        
        <li>July 31, 2026: Deadline for full papers submission.</li>
        
        <li>October 31, 2026: Initial feedback to authors.</li>
        
        <li>January 31, 2027: Deadline for resubmission of revised papers.</li>
        
        <li>April 30, 2027: Second-round feedback to authors.</li>
        
        <li>June 30, 2027: Final editorial decisions communicated to authors.</li>
        
    </ul>
    
    
    <h2>Associate editors</h2>
    <ul>
        
        <li><strong>Ahmad Arslan</strong>, University of Oulu</li>
        
        <li><strong>Alexander Richter</strong>, Victoria University of Wellington</li>
        
        <li><strong>Daniel Gozman</strong>, University of Sydney</li>
        
        <li><strong>Eleonora Pantano</strong>, University of Bristol</li>
        
        <li><strong>Federico Iannacci</strong>, University of Sussex</li>
        
        <li><strong>Francis Andoh Baidoo</strong>, University of Texas Rio Grande Valley</li>
        
        <li><strong>Imran Ali</strong>, Central Queensland University</li>
        
        <li><strong>Ismail Golgeci</strong>, University of Auckland</li>
        
        <li><strong>Jason Bennett Thatcher</strong>, University of Colorado Boulder</li>
        
        <li><strong>Linda Hollebeek</strong>, Sunway University</li>
        
        <li><strong>Margherita Pagani</strong>, SKEMA Business School</li>
        
        <li><strong>Nisreen Ameen</strong>, Royal Holloway</li>
        
        <li><strong>Ryan Yung</strong>, University of Greenwich</li>
        
        <li><strong>Saima Qutab</strong>, University of Auckland</li>
        
        <li><strong>Sandra Smith</strong>, University of Auckland</li>
        
        <li><strong>Shohil Kishore</strong>, University of Auckland</li>
        
        <li><strong>Stan Karanasios</strong>, University of Queensland</li>
        
        <li><strong>Weng Marc Lim</strong>, Sunway University</li>
        
    </ul>
    
</div>]]></content:encoded>
            <author>The Journal of Strategic Information Systems (JSIS)</author>
        </item>
        <item>
            <title><![CDATA[Managing the Individual, Organizational, and Societal Challenges of Generative AI: Utopian, Dystopian, Neutropian Perspectives]]></title>
            <link>https://callsforpapers.org/call/jais-managing-the-individual-organizational-and-societal-challenges-of-generative-ai-utopian-dystopian-neutropian-perspectives</link>
            <guid>jais-managing-the-individual-organizational-and-societal-challenges-of-generative-ai-utopian-dystopian-neutropian-perspectives</guid>
            <pubDate>Tue, 13 Jun 2023 12:46:46 GMT</pubDate>
            <content:encoded><![CDATA[<div>
    
        
        <p><strong>Varun Grover</strong>, University of Arkansas</p>
        
        <p><strong>Arpan Kumar Kar</strong>, Indian Institute of Technology Delhi</p>
        
        <p><strong>Rajiv Sabherwal</strong>, University of Arkansas</p>
        
        <p><strong>Spyros Angelopoulos</strong>, Durham University</p>
        
        <p><strong>Hartmut Hoehle</strong>, University of Mannheim</p>
        
        <p><strong>Anik Mukherjee</strong>, Indian Institute of Management</p>
        
    
    
    <p>The origins of generative AI (GAI) can be traced back to the 1950s, when Alan Turing proposed a test to determine whether a machine could be perceived as intelligent enough to generate responses to questions in a way indistinguishable from a human. Later, in the 1970s, researchers developed more advanced models capable of producing more realistic and coherent outcomes. Contemporary GAI models are based on state-of-the-art neural network architectures. They combine such architectures to develop large models that outperform existing benchmarked ones. Contemporary GAI solutions can produce large amounts of contextual outputs on any specific topic. They are highly trained and sophisticated, enabling users to produce various types of AI-generated content. Although GAI has been around for a while, recent developments have brought the potential of such solutions to the forefront. In particular, LLMs have the potential to transform the way we develop textual content and communicate with one another.</p>
    
    <p>The ongoing discourse on GAI seems to extol the promises of AI and the dangers. Our goal for this Special Issue is to offer a careful examination of the challenges faced in managing this powerful set of technologies for individuals, organizations, and society. Many of the challenges around GAI concern data. As per a Forbes report, over 90% of internet data will be produced by GAI models, triggering serious concerns about harmful and abusive content generation. Most current GAI-triggered use involves chat-based digital assistants. While the outcome of GAI in these digital assistant-based applications is indeed remarkable, their effectiveness depends on the level of task specificity and the need for information synthesis.</p>
    
    <p>At the individual level, a number of challenges exist on how to effectively use GAI to augment individual productivity. For instance, how can GAI-based interactions positively or negatively affect customer experiences, how can GAI augment (vs. replace) human skills, and broader questions of how over-reliance on GAI systems may adversely impact the cognitive inability of users and learners. At the organizational level, there are many challenges around governance. For instance, how can we govern the quality of content by GAI, how can the adoption of GAI lead to disruption, how do we set up appropriate governance structures to manage GAI projects, and how can we avoid unintended consequences of GAI adoption in firms? At the societal level, there are extensive challenges around misinformation, bias, and privacy. Our broad goal for the special issue is to attract papers that articulate the challenges theoretically and study them empirically, while making a strong contribution to the theory and practice in the deployment of GAI.</p>
    
    
    <h2>Potential topics</h2>
    <ul>
        
        <li>Challenges in managing GAI for individuals, organizations, and society</li>
        
        <li>Impact of GAI on individual productivity and customer experiences</li>
        
        <li>Governance challenges related to content quality generated by GAI</li>
        
        <li>Misinformation and privacy issues at the societal level</li>
        
    </ul>
    
    
    <h2>Timeline</h2>
    <ul>
        
        <li>August 31, 2024: Article Submission Deadline</li>
        
        <li>November 30, 2024: First Review</li>
        
        <li>July 31, 2026: Article Final Decision</li>
        
    </ul>
    
    
    <h2>Associate editors</h2>
    <ul>
        
        <li><strong>Shahriar Akter</strong>, University of Wollongong</li>
        
        <li><strong>Hillol Bala</strong>, Indiana University</li>
        
        <li><strong>Kevin Bauer</strong>, University of Mannheim</li>
        
        <li><strong>Roberta Bernardi</strong>, University of Bristol</li>
        
        <li><strong>Michael Chau</strong>, The University of Hong Kong</li>
        
        <li><strong>Alain Chong</strong>, University of Nottingham Ningbo China</li>
        
        <li><strong>Kieran Conboy</strong>, National University of Ireland Galway</li>
        
        <li><strong>Yogesh Dwivedi</strong>, Swansea University</li>
        
        <li><strong>Amany Elbanna</strong>, Royal Holloway University of London</li>
        
        <li><strong>Weiguo (Patrick) Fan</strong>, University of Iowa</li>
        
        <li><strong>Sumeet Gupta</strong>, Indian Institute of Management Raipur</li>
        
        <li><strong>Karlheinz Kautz</strong>, RMIT University</li>
        
        <li><strong>Stan Karaniosis</strong>, University of Queensland</li>
        
        <li><strong>Yeongin Kim</strong>, Virginia Commonwealth</li>
        
        <li><strong>Ajay Kumar</strong>, EM Lyon</li>
        
        <li><strong>Marijn Janssen</strong>, TU Delft</li>
        
        <li><strong>Agam Gupta</strong>, Indian Institute of Technology Delhi</li>
        
        <li><strong>Shivam Gupta</strong>, NEOMA Business School</li>
        
        <li><strong>Taha Havakhor</strong>, McGill University</li>
        
        <li><strong>Mary Lacity</strong>, University of Arkansas</li>
        
        <li><strong>Xin (Robert) Luo</strong>, University of New Mexico</li>
        
        <li><strong>Patrick Mikalef</strong>, Norwegian University of Science &amp; Tech</li>
        
        <li><strong>Ilias O Pappas</strong>, University of Agder</li>
        
        <li><strong>Uthaysankar Sivarajah</strong>, University of Bradford</li>
        
        <li><strong>Kai Spohrer</strong>, Frankfurt School of Finance and Management</li>
        
        <li><strong>Sujeet Sharma</strong>, Indian Institute of Management Nagpur</li>
        
        <li><strong>Samuel Fosso Wamba</strong>, Toulouse Business School</li>
        
        <li><strong>Amber Young</strong>, University of Arkansas</li>
        
    </ul>
    
</div>]]></content:encoded>
            <author>Journal of the Association for Information Systems (JAIS)</author>
        </item>
    </channel>
</rss>